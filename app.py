# app.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, ConfusionMatrixDisplay,
    roc_curve, auc, RocCurveDisplay
)
import train_model  # Importamos nuestro mÃ³dulo de entrenamiento

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="PredicciÃ³n de Fallos de MÃ¡quina",
    page_icon="âš™ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# TÃ­tulo principal
st.title("âš™ï¸ Sistema de PredicciÃ³n de Fallos de MÃ¡quina")
st.markdown("---")

# ============================================================
# MENÃš PRINCIPAL MEJORADO EN SIDEBAR
# ============================================================
with st.sidebar:
    st.image("https://img.icons8.com/fluency/96/machine-learning.png", width=80)
    st.title("ğŸ§­ MenÃº de NavegaciÃ³n")
    st.markdown("---")
    
    # MenÃº principal con iconos
    menu_opcion = st.radio(
        "**Secciones principales:**",
        [
            "ğŸ  Inicio", 
            "ğŸ“Š AnÃ¡lisis de Datos", 
            "ğŸ¤– Entrenar Modelo", 
            "ğŸ”® Predecir Fallos",
            "ğŸ“ˆ Rendimiento del Modelo",
            "âš™ï¸ ConfiguraciÃ³n"
        ],
        index=0
    )
    
    st.markdown("---")
    st.subheader("ğŸš€ Acciones RÃ¡pidas")
    
    # Botones de acciÃ³n rÃ¡pida
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ”„ Entrenar", help="Entrenar modelo rÃ¡pido"):
            menu_opcion = "ğŸ¤– Entrenar Modelo"
    with col2:
        if st.button("ğŸ” Predecir", help="Ir a predicciÃ³n"):
            menu_opcion = "ğŸ”® Predecir Fallos"
    
    st.markdown("---")
    st.caption("v1.0 | Sistema de PredicciÃ³n Inteligente")

# ============================================================
# SECCIÃ“N: INICIO
# ============================================================
if menu_opcion == "ğŸ  Inicio":
    st.header("ğŸ  Bienvenido al Sistema de PredicciÃ³n de Fallos")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### Â¿QuÃ© puedes hacer con esta aplicaciÃ³n?
        
        - **ğŸ“Š AnÃ¡lisis de Datos**: Explora y visualiza los datos de sensores
        - **ğŸ¤– Entrenar Modelo**: Entrena modelos de machine learning
        - **ğŸ”® Predecir Fallos**: Realiza predicciones en tiempo real
        - **ğŸ“ˆ Rendimiento**: EvalÃºa el desempeÃ±o del modelo
        - **âš™ï¸ ConfiguraciÃ³n**: Ajusta parÃ¡metros del sistema
        
        ### ğŸ“‹ Dataset de Machine Failure Prediction
        Datos de sensores para predecir fallos en mÃ¡quinas con:
        - 9 caracterÃ­sticas de sensores
        - Variable objetivo binaria (fallo/no fallo)
        - Datos limpios y preprocesados
        """)
    
    with col2:
        st.info("""
        **ğŸ“Š EstadÃ­sticas rÃ¡pidas:**
        - 943 registros
        - 10 caracterÃ­sticas
        - 2 clases (0: Normal, 1: Fallo)
        - 0 valores nulos
        """)
        
        # Mini visualizaciÃ³n
        try:
            df = pd.read_csv("data.csv")
            counts = df['fail'].value_counts()
            st.metric("Registros con fallo", f"{counts.get(1, 0)}")
            st.metric("Registros normales", f"{counts.get(0, 0)}")
        except:
            st.warning("Dataset no disponible")

# ============================================================
# SECCIÃ“N: ANÃLISIS DE DATOS (MANTIENE TU CÃ“DIGO ORIGINAL)
# ============================================================
elif menu_opcion == "ğŸ“Š AnÃ¡lisis de Datos":
    st.header("ğŸ“Š AnÃ¡lisis Exploratorio de Datos")
    
    # Cargar datos
    @st.cache_data
    def load_data():
        return pd.read_csv("data.csv")
    
    df = load_data()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ Primeras filas del dataset")
        st.dataframe(df.head(10), use_container_width=True)
        
        st.subheader("ğŸ“ˆ EstadÃ­sticas descriptivas")
        st.dataframe(df.describe(), use_container_width=True)
    
    with col2:
        st.subheader("ğŸ“Š DistribuciÃ³n de Fallos")
        counts = df['fail'].value_counts()
        st.bar_chart(counts)
        
        st.subheader("â„¹ï¸ InformaciÃ³n del dataset")
        st.write(f"**ğŸ“ Filas:** {df.shape[0]}")
        st.write(f"**ğŸ“Š Columnas:** {df.shape[1]}")
        st.write(f"**ğŸ” Valores nulos:** {df.isnull().sum().sum()}")
        st.write(f"**âš–ï¸ Balance de clases:**")
        st.write(f"  - Normal (0): {counts.get(0, 0)} registros")
        st.write(f"  - Fallo (1): {counts.get(1, 0)} registros")

# ============================================================
# SECCIÃ“N: ENTRENAR MODELO (MANTIENE TU CÃ“DIGO ORIGINAL)
# ============================================================
elif menu_opcion == "ğŸ¤– Entrenar Modelo":
    st.header("ğŸ¤– Entrenamiento del Modelo")
    
    with st.expander("âš™ï¸ Opciones avanzadas de entrenamiento", expanded=False):
        use_gridsearch = st.checkbox(
            "Ejecutar GridSearchCV (MUY LENTO - solo para experimentaciÃ³n)",
            value=False,
            help="BuscarÃ¡ los mejores parÃ¡metros desde cero. Puede tomar varios minutos. Solo para uso experimental."
        )
    
    if use_gridsearch:
        st.warning("âš ï¸ **MODO EXPERIMENTAL ACTIVADO**: El entrenamiento serÃ¡ mucho mÃ¡s lento pero puede encontrar parÃ¡metros mÃ¡s Ã³ptimos.")
    else:
        st.info("""
        Esta acciÃ³n entrenarÃ¡ un modelo de Logistic Regression con los mejores parÃ¡metros encontrados:
        - **Penalty**: L1
        - **C**: 1  
        - **Solver**: liblinear
        - **Class Weight**: None
        """)
    
    if st.button("ğŸš€ Iniciar Entrenamiento", type="primary", use_container_width=True):
        with st.spinner("ğŸ§  Entrenando modelo... Esto puede tomar unos segundos"):
            try:
                metrics = train_model.train_and_save_model(use_gridsearch=use_gridsearch)
                
                st.success("âœ… Â¡Modelo entrenado exitosamente!")
                
                # Mostrar mÃ©tricas en columnas
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("ğŸ¯ PrecisiÃ³n", f"{metrics['accuracy']:.4f}")
                
                with col2:
                    st.metric("ğŸ’¾ Modelo", "lr_best.pkl")
                
                with col3:
                    st.metric("ğŸ“ Scaler", "scaler.pkl")
                
                # InformaciÃ³n del modo usado
                if metrics.get('used_gridsearch', False):
                    st.info("ğŸ” **Modo usado**: GridSearchCV")
                    if metrics.get('best_params'):
                        st.write("**Mejores parÃ¡metros encontrados:**", metrics['best_params'])
                else:
                    st.info("ğŸš€ **Modo usado**: ParÃ¡metros pre-optimizados")
                    st.write("**ParÃ¡metros usados:**", metrics.get('best_params', {}))
                
                # Reporte de clasificaciÃ³n
                st.subheader("ğŸ“Š Reporte de ClasificaciÃ³n")
                report_df = pd.DataFrame(metrics['classification_report']).transpose()
                st.dataframe(report_df.style.highlight_max(axis=0), use_container_width=True)
                
            except Exception as e:
                st.error(f"âŒ Error durante el entrenamiento: {str(e)}")

# ============================================================
# SECCIÃ“N: PREDECIR FALLOS (MANTIENE TU CÃ“DIGO ORIGINAL)
# ============================================================
elif menu_opcion == "ğŸ”® Predecir Fallos":
    st.header("ğŸ”® PredicciÃ³n de Fallos en Tiempo Real")
    
    try:
        model = joblib.load('lr_best.pkl')
        scaler = joblib.load('scaler.pkl')
        st.success("âœ… Modelo y scaler cargados exitosamente!")
        
        st.subheader("ğŸ›ï¸ Ingresa los valores de los sensores:")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            footfall = st.number_input("Footfall", min_value=0.0, value=25.0, help="NÃºmero de personas u objetos pasando")
            tempMode = st.number_input("Temp Mode", min_value=0.0, value=1.0, help="Modo de temperatura")
            AQ = st.number_input("AQ", min_value=0.0, value=50.0, help="Calidad del aire")
        
        with col2:
            USS = st.number_input("USS", min_value=0.0, value=100.0, help="Sensor ultrasÃ³nico")
            CS = st.number_input("CS", min_value=0.0, value=2.5, help="Sensor de corriente")
            VOC = st.number_input("VOC", min_value=0.0, value=2500.0, help="Compuestos orgÃ¡nicos volÃ¡tiles")
        
        with col3:
            RP = st.number_input("RP", min_value=0.0, value=35.0, help="PosiciÃ³n rotacional")
            IP = st.number_input("IP", min_value=0.0, value=50.0, help="PresiÃ³n de entrada")
            Temperature = st.number_input("Temperature", min_value=0.0, value=60.0, help="Temperatura operativa")
        
        if st.button("ğŸ” Realizar PredicciÃ³n", type="primary", use_container_width=True):
            input_data = np.array([[footfall, tempMode, AQ, USS, CS, VOC, RP, IP, Temperature]])
            input_scaled = scaler.transform(input_data)
            
            prediction = model.predict(input_scaled)
            probability = model.predict_proba(input_scaled)
            
            st.markdown("---")
            st.subheader("ğŸ“‹ Resultado de la PredicciÃ³n")
            
            if prediction[0] == 1:
                st.error("ğŸš¨ **PREDICCIÃ“N: FALLO INMINENTE**")
                st.write(f"ğŸ“Š Probabilidad de fallo: {probability[0][1]:.2%}")
            else:
                st.success("âœ… **PREDICCIÃ“N: MÃQUINA EN ESTADO NORMAL**")
                st.write(f"ğŸ“Š Probabilidad de fallo: {probability[0][1]:.2%}")
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric("âœ… Probabilidad de NO fallo", f"{probability[0][0]:.2%}")
            with col2:
                st.metric("âŒ Probabilidad de fallo", f"{probability[0][1]:.2%}")
                
    except FileNotFoundError:
        st.warning("âš ï¸ Modelo no encontrado. Entrena el modelo primero.")

# ============================================================
# SECCIÃ“N: RENDIMIENTO (CORREGIDA Y COMPLETA)
# ============================================================
elif menu_opcion == "ğŸ“ˆ Rendimiento del Modelo":
    st.header("ğŸ“ˆ Rendimiento y MÃ©tricas del Modelo")
    
    try:
        # Cargar modelo, scaler y datos
        model = joblib.load('lr_best.pkl')
        scaler = joblib.load('scaler.pkl')
        df = pd.read_csv("data.csv")
        
        # Preparar datos para evaluaciÃ³n
        X = df.drop('fail', axis=1)
        y = df['fail']  # âœ… DEFINIMOS y AQUÃ
        X_scaled = scaler.transform(X)
        
        # Realizar predicciones âœ… DEFINIMOS y_pred AQUÃ
        y_pred = model.predict(X_scaled)
        y_pred_proba = model.predict_proba(X_scaled)[:, 1]
        
        st.success("âœ… Modelo y datos cargados exitosamente!")
        
        # PestaÃ±as para organizar las mÃ©tricas
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“Š MÃ©tricas BÃ¡sicas", "ğŸ“‹ Reporte Completo", "ğŸ¯ Matriz de ConfusiÃ³n", "ğŸ“ˆ Curva ROC"])
        
        with tab1:
            st.subheader("ğŸ“Š MÃ©tricas BÃ¡sicas de Rendimiento")
            
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            # âœ… AHORA y e y_pred ESTÃN DEFINIDAS
            accuracy = accuracy_score(y, y_pred)
            precision = precision_score(y, y_pred)
            recall = recall_score(y, y_pred)
            f1 = f1_score(y, y_pred)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("PrecisiÃ³n (Accuracy)", f"{accuracy:.4f}")
            with col2:
                st.metric("PrecisiÃ³n (Precision)", f"{precision:.4f}")
            with col3:
                st.metric("Sensibilidad (Recall)", f"{recall:.4f}")
            with col4:
                st.metric("PuntuaciÃ³n F1", f"{f1:.4f}")
            
            # GrÃ¡fico de barras de mÃ©tricas
            metrics_data = {
                'MÃ©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
                'Valor': [accuracy, precision, recall, f1]
            }
            metrics_df = pd.DataFrame(metrics_data)
            st.bar_chart(metrics_df.set_index('MÃ©trica'))
        
        with tab2:
            st.subheader("ğŸ“‹ Reporte de ClasificaciÃ³n Completo")
            
            from sklearn.metrics import classification_report
            
            # âœ… AHORA y e y_pred ESTÃN DEFINIDAS
            report = classification_report(y, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            
            st.dataframe(
                report_df.style
                .highlight_max(axis=0, color='#90EE90')
                .format('{:.4f}'),
                use_container_width=True
            )
            
            # Descargar reporte
            csv = report_df.to_csv(index=True)
            st.download_button(
                label="ğŸ“¥ Descargar Reporte CSV",
                data=csv,
                file_name="reporte_clasificacion.csv",
                mime="text/csv"
            )
        
        with tab3:
            st.subheader("ğŸ¯ Matriz de ConfusiÃ³n")
            
            from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
            import matplotlib.pyplot as plt
            
            # âœ… AHORA y e y_pred ESTÃN DEFINIDAS
            cm = confusion_matrix(y, y_pred)
            
            fig, ax = plt.subplots(figsize=(6, 5))
            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Fallo'])
            disp.plot(cmap='Blues', ax=ax, values_format='d')
            plt.title('Matriz de ConfusiÃ³n')
            st.pyplot(fig)
            
            # AnÃ¡lisis de la matriz
            st.info("**AnÃ¡lisis de la matriz:**")
            st.write(f"- **Verdaderos Negativos (TN):** {cm[0, 0]}")
            st.write(f"- **Falsos Positivos (FP):** {cm[0, 1]}")
            st.write(f"- **Falsos Negativos (FN):** {cm[1, 0]}")
            st.write(f"- **Verdaderos Positivos (TP):** {cm[1, 1]}")
        
        with tab4:
            st.subheader("ğŸ“ˆ Curva ROC y AUC")
            
            from sklearn.metrics import roc_curve, auc, RocCurveDisplay
            import matplotlib.pyplot as plt
            
            # âœ… AHORA y e y_pred_proba ESTÃN DEFINIDAS
            fpr, tpr, thresholds = roc_curve(y, y_pred_proba)
            roc_auc = auc(fpr, tpr)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            RocCurveDisplay.from_predictions(
                y, y_pred_proba,
                name=f"ROC curve (AUC = {roc_auc:.4f})",
                ax=ax
            )
            plt.plot([0, 1], [0, 1], 'k--', label='Clasificador aleatorio')
            plt.xlabel('Tasa de Falsos Positivos')
            plt.ylabel('Tasa de Verdaderos Positivos')
            plt.title('Curva ROC')
            plt.legend(loc='lower right')
            st.pyplot(fig)
            
            st.metric("Ãrea bajo la curva (AUC)", f"{roc_auc:.4f}")
            
            # InterpretaciÃ³n del AUC
            if roc_auc > 0.9:
                st.success("âœ… Excelente poder de discriminaciÃ³n (AUC > 0.9)")
            elif roc_auc > 0.8:
                st.warning("âš ï¸ Buen poder de discriminaciÃ³n (AUC > 0.8)")
            else:
                st.error("âŒ Poder de discriminaciÃ³n limitado (AUC < 0.8)")
        
        # SecciÃ³n adicional de anÃ¡lisis
        st.markdown("---")
        st.subheader("ğŸ“Œ AnÃ¡lisis Adicional")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # DistribuciÃ³n de probabilidades
            st.write("**DistribuciÃ³n de probabilidades predichas:**")
            prob_df = pd.DataFrame({
                'Probabilidad': y_pred_proba,
                'Clase Real': y.map({0: 'Normal', 1: 'Fallo'})
            })
            st.bar_chart(prob_df.groupby('Clase Real')['Probabilidad'].mean())
        
        with col2:
            # MÃ©tricas por clase
            st.write("**Resumen por clase:**")
            class_summary = pd.DataFrame({
                'Clase': ['Normal (0)', 'Fallo (1)'],
                'Registros': [len(y[y == 0]), len(y[y == 1])],
                'PrecisiÃ³n': [report['0']['precision'], report['1']['precision']],
                'Recall': [report['0']['recall'], report['1']['recall']]
            })
            st.dataframe(class_summary, use_container_width=True)
                
    except FileNotFoundError:
        st.error("""
        âŒ No se encontraron los archivos necesarios. Por favor:
        1. Ve a la secciÃ³n **ğŸ¤– Entrenar Modelo**
        2. Entrena el modelo primero
        3. Vuelve a esta secciÃ³n
        """)
    except Exception as e:
        st.error(f"âŒ Error al cargar los datos: {str(e)}")

# ============================================================
# SECCIÃ“N: CONFIGURACIÃ“N (NUEVA)
# ============================================================
elif menu_opcion == "âš™ï¸ ConfiguraciÃ³n":
    st.header("âš™ï¸ ConfiguraciÃ³n del Sistema")
    
    st.subheader("ğŸ”§ Ajustes de la AplicaciÃ³n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.selectbox("Tema de la aplicaciÃ³n", ["Claro", "Oscuro"])
        st.slider("TamaÃ±o de visualizaciÃ³n", 1, 100, 80)
    
    with col2:
        st.number_input("LÃ­mite de registros", 100, 10000, 1000)
        st.checkbox("Modo de alto contraste")
    
    st.subheader("ğŸ“ GestiÃ³n de Archivos")
    if st.button("ğŸ—‘ï¸ Limpiar modelos antiguos"):
        st.info("FunciÃ³n de limpieza en desarrollo...")
    
    st.subheader("â„¹ï¸ InformaciÃ³n del Sistema")
    st.write(f"**VersiÃ³n de Streamlit:** {st.__version__}")
    st.write("**Estado:** ğŸŸ¢ Conectado")

# Footer
st.markdown("---")
st.caption("Â© 2024 Sistema de predicciÃ³n de fallos de mÃ¡quina | Desarrollado con Streamlit y Machine Learning")