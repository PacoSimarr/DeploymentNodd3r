# app.py
import streamlit as st
import pandas as pd
import numpy as np
import joblib
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, ConfusionMatrixDisplay,
    roc_curve, auc, RocCurveDisplay
)
import train_model  # Importamos nuestro m√≥dulo de entrenamiento

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Predicci√≥n de Fallos de M√°quina",
    page_icon="‚öôÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo principal
st.title("‚öôÔ∏è Sistema de Predicci√≥n de Fallos de M√°quina")
st.markdown("---")

# ============================================================
# MEN√ö PRINCIPAL MEJORADO EN SIDEBAR
# ============================================================
with st.sidebar:
    st.image("https://img.icons8.com/fluency/96/machine-learning.png", width=80)
    st.title("üß≠ Men√∫ de Navegaci√≥n")
    st.markdown("---")
    
    # Men√∫ principal con iconos
    menu_opcion = st.radio(
        "**Secciones principales:**",
        [
            "üè† Inicio", 
            "üìä An√°lisis de Datos", 
            "ü§ñ Entrenar Modelo", 
            "üîÆ Predecir Fallos",
            "üìà Rendimiento del Modelo",
            "‚öôÔ∏è Configuraci√≥n"
        ],
        index=0
    )
    
    st.markdown("---")
    st.subheader("üöÄ Acciones R√°pidas")
    
    # Botones de acci√≥n r√°pida
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üîÑ Entrenar", help="Entrenar modelo r√°pido"):
            menu_opcion = "ü§ñ Entrenar Modelo"
    with col2:
        if st.button("üîç Predecir", help="Ir a predicci√≥n"):
            menu_opcion = "üîÆ Predecir Fallos"
    
    st.markdown("---")
    st.caption("v1.0 | Sistema de Predicci√≥n Inteligente")

# ============================================================
# SECCI√ìN: INICIO
# ============================================================
if menu_opcion == "üè† Inicio":
    st.header("üè† Bienvenido al Sistema de Predicci√≥n de Fallos")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### ¬øQu√© puedes hacer con esta aplicaci√≥n?
        
        - **üìä An√°lisis de Datos**: Explora y visualiza los datos de sensores
        - **ü§ñ Entrenar Modelo**: Entrena modelos de machine learning
        - **üîÆ Predecir Fallos**: Realiza predicciones en tiempo real
        - **üìà Rendimiento**: Eval√∫a el desempe√±o del modelo
        - **‚öôÔ∏è Configuraci√≥n**: Ajusta par√°metros del sistema
        
        ### üìã Dataset de Machine Failure Prediction
        Datos de sensores para predecir fallos en m√°quinas con:
        - 9 caracter√≠sticas de sensores
        - Variable objetivo binaria (fallo/no fallo)
        - Datos limpios y preprocesados
        """)
    
    with col2:
        st.info("""
        **üìä Estad√≠sticas r√°pidas:**
        - 943 registros
        - 10 caracter√≠sticas
        - 2 clases (0: Normal, 1: Fallo)
        - 0 valores nulos
        """)
        
        # Mini visualizaci√≥n
        try:
            df = pd.read_csv("data.csv")
            counts = df['fail'].value_counts()
            st.metric("Registros con fallo", f"{counts.get(1, 0)}")
            st.metric("Registros normales", f"{counts.get(0, 0)}")
        except:
            st.warning("Dataset no disponible")

# ============================================================
# SECCI√ìN: AN√ÅLISIS DE DATOS
# ============================================================
elif menu_opcion == "üìä An√°lisis de Datos":
    st.header("üìä An√°lisis Exploratorio de Datos")
    
    # Cargar datos
    @st.cache_data
    def load_data():
        return pd.read_csv("data.csv")
    
    try:
        df = load_data()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("üìã Primeras filas del dataset")
            st.dataframe(df.head(10), use_container_width=True)
            
            st.subheader("üìà Estad√≠sticas descriptivas")
            st.dataframe(df.describe(), use_container_width=True)
        
        with col2:
            st.subheader("üìä Distribuci√≥n de Fallos")
            counts = df['fail'].value_counts()
            fig, ax = plt.subplots()
            ax.bar(['Normal (0)', 'Fallo (1)'], counts.values, color=['green', 'red'])
            ax.set_ylabel('Cantidad de Registros')
            ax.set_title('Distribuci√≥n de Clases')
            st.pyplot(fig)
            
            st.subheader("‚ÑπÔ∏è Informaci√≥n del dataset")
            st.write(f"**üìè Filas:** {df.shape[0]}")
            st.write(f"**üìä Columnas:** {df.shape[1]}")
            st.write(f"**üîç Valores nulos:** {df.isnull().sum().sum()}")
            st.write(f"**‚öñÔ∏è Balance de clases:**")
            st.write(f"  - Normal (0): {counts.get(0, 0)} registros")
            st.write(f"  - Fallo (1): {counts.get(1, 0)} registros")
    
    except FileNotFoundError:
        st.error("‚ùå No se encontr√≥ el archivo data.csv")
    except Exception as e:
        st.error(f"‚ùå Error al cargar los datos: {str(e)}")

# ============================================================
# SECCI√ìN: ENTRENAR MODELO
# ============================================================
elif menu_opcion == "ü§ñ Entrenar Modelo":
    st.header("ü§ñ Entrenamiento del Modelo")
    
    with st.expander("‚öôÔ∏è Opciones avanzadas de entrenamiento", expanded=False):
        use_gridsearch = st.checkbox(
            "Ejecutar GridSearchCV (MUY LENTO - solo para experimentaci√≥n)",
            value=False,
            help="Buscar√° los mejores par√°metros desde cero. Puede tomar varios minutos. Solo para uso experimental."
        )
    
    if use_gridsearch:
        st.warning("‚ö†Ô∏è **MODO EXPERIMENTAL ACTIVADO**: El entrenamiento ser√° mucho m√°s lento pero puede encontrar par√°metros m√°s √≥ptimos.")
    else:
        st.info("""
        Esta acci√≥n entrenar√° un modelo de Logistic Regression con los mejores par√°metros encontrados:
        - **Penalty**: L1
        - **C**: 1  
        - **Solver**: liblinear
        - **Class Weight**: None
        """)
    
    if st.button("üöÄ Iniciar Entrenamiento", type="primary", use_container_width=True):
        with st.spinner("üß† Entrenando modelo... Esto puede tomar unos segundos"):
            try:
                metrics = train_model.train_and_save_model(use_gridsearch=use_gridsearch)
                
                st.success("‚úÖ ¬°Modelo entrenado exitosamente!")
                
                # Mostrar m√©tricas en columnas
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.metric("üéØ Precisi√≥n", f"{metrics['accuracy']:.4f}")
                
                with col2:
                    st.metric("üíæ Modelo", "lr_best.pkl")
                
                with col3:
                    st.metric("üìê Scaler", "scaler.pkl")
                
                # Informaci√≥n del modo usado
                if metrics.get('used_gridsearch', False):
                    st.info("üîç **Modo usado**: GridSearchCV")
                    if metrics.get('best_params'):
                        st.write("**Mejores par√°metros encontrados:**", metrics['best_params'])
                else:
                    st.info("üöÄ **Modo usado**: Par√°metros pre-optimizados")
                    st.write("**Par√°metros usados:**", metrics.get('best_params', {}))
                
                # Reporte de clasificaci√≥n
                st.subheader("üìä Reporte de Clasificaci√≥n")
                report_df = pd.DataFrame(metrics['classification_report']).transpose()
                st.dataframe(report_df.style.highlight_max(axis=0), use_container_width=True)
                
            except Exception as e:
                st.error(f"‚ùå Error durante el entrenamiento: {str(e)}")

# ============================================================
# SECCI√ìN: PREDECIR FALLOS - CON SHAP INTEGRADO (ACTUALIZADO)
# ============================================================
elif menu_opcion == "üîÆ Predecir Fallos":
    st.header("üîÆ Predicci√≥n de Fallos en Tiempo Real")
    
    # Crear pesta√±as separadas
    tab_pred, tab_analysis, tab_explain = st.tabs(["üéØ Realizar Predicci√≥n", "üìä An√°lisis Dataset", "üìù Explicaci√≥n del Modelo (SHAP)"])
    
    # PESTA√ëA 1: PREDICCI√ìN
    with tab_pred:
        st.subheader("üéØ Ingresa los valores del sensor para predecir")
        
        try:
            model = joblib.load('lr_best.pkl')
            scaler = joblib.load('scaler.pkl')
            df = pd.read_csv("data.csv")  # Cargar datos para el explainer
            
            st.success("‚úÖ Modelo, scaler y datos cargados exitosamente!")
            
            # Formulario de entrada MEJORADO
            st.markdown("### üéõÔ∏è Valores de los Sensores")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                footfall = st.number_input("Footfall", min_value=0.0, value=25.0, help="N√∫mero de personas u objetos pasando")
                tempMode = st.number_input("Temp Mode", min_value=0.0, value=1.0, help="Modo de temperatura")
                AQ = st.number_input("AQ", min_value=0.0, value=50.0, help="Calidad del aire")
            
            with col2:
                USS = st.number_input("USS", min_value=0.0, value=100.0, help="Sensor ultras√≥nico")
                CS = st.number_input("CS", min_value=0.0, value=2.5, help="Sensor de corriente")
                VOC = st.number_input("VOC", min_value=0.0, value=2500.0, help="Compuestos org√°nicos vol√°tiles")
            
            with col3:
                RP = st.number_input("RP", min_value=0.0, value=35.0, help="Posici√≥n rotacional")
                IP = st.number_input("IP", min_value=0.0, value=50.0, help="Presi√≥n de entrada")
                Temperature = st.number_input("Temperature", min_value=0.0, value=60.0, help="Temperatura operativa")
            
            # Bot√≥n de predicci√≥n
            if st.button("üîç Realizar Predicci√≥n", type="primary", use_container_width=True):
                input_data = np.array([[footfall, tempMode, AQ, USS, CS, VOC, RP, IP, Temperature]])
                input_scaled = scaler.transform(input_data)
                
                prediction = model.predict(input_scaled)
                probability = model.predict_proba(input_scaled)
                
                # RESULTADO CLARO Y VISIBLE
                st.markdown("---")
                st.success("### üìã Resultado de la Predicci√≥n")
                
                if prediction[0] == 1:
                    st.error("""
                    üö® **PREDICCI√ìN: FALLO INMINENTE**
                    
                    **Recomendaciones:**
                    - Detener m√°quina inmediatamente
                    - Revisar sensores cr√≠ticos
                    - Contactar con mantenimiento
                    """)
                    st.write(f"üìä **Probabilidad de fallo:** {probability[0][1]:.2%}")
                else:
                    st.success("""
                    ‚úÖ **PREDICCI√ìN: M√ÅQUINA EN ESTADO NORMAL**
                    
                    **Recomendaciones:**
                    - Continuar operaci√≥n normal
                    - Monitoreo rutinario
                    - Mantenimiento preventivo programado
                    """)
                    st.write(f"üìä **Probabilidad de fallo:** {probability[0][1]:.2%}")
                
                # M√©tricas de probabilidad
                col_met1, col_met2 = st.columns(2)
                with col_met1:
                    st.metric("‚úÖ Probabilidad de NO fallo", f"{probability[0][0]:.2%}")
                with col_met2:
                    st.metric("‚ùå Probabilidad de fallo", f"{probability[0][1]:.2%}")
                
                # Visualizaci√≥n de probabilidades
                st.markdown("---")
                st.subheader("üìä Visualizaci√≥n de Probabilidades")
                
                prob_data = {
                    'Estado': ['NO FALLO', 'FALLO'],
                    'Probabilidad': [probability[0][0], probability[0][1]]
                }
                prob_df = pd.DataFrame(prob_data)
                
                fig, ax = plt.subplots(figsize=(10, 4))
                bars = ax.barh(prob_df['Estado'], prob_df['Probabilidad'], 
                              color=['green', 'red'], alpha=0.7)
                
                # A√±adir valores en las barras
                for i, (value, state) in enumerate(zip(prob_df['Probabilidad'], prob_df['Estado'])):
                    ax.text(value + 0.01, i, f'{value:.2%}', va='center', fontweight='bold')
                
                ax.set_xlim(0, 1)
                ax.set_xlabel('Probabilidad')
                ax.set_title('Distribuci√≥n de Probabilidades de Predicci√≥n')
                st.pyplot(fig)
                
                # Guardar los datos de entrada para usar en la pesta√±a de explicaci√≥n
                st.session_state['input_data'] = input_data
                st.session_state['input_scaled'] = input_scaled
                st.session_state['prediction'] = prediction
                st.session_state['probability'] = probability
                    
        except FileNotFoundError:
            st.warning("‚ö†Ô∏è Modelo no encontrado. Por favor, entrena el modelo primero en la secci√≥n 'ü§ñ Entrenar Modelo'.")
        except Exception as e:
            st.error(f"‚ùå Error al realizar la predicci√≥n: {str(e)}")
    
    # PESTA√ëA 2: AN√ÅLISIS
    with tab_analysis:
        st.subheader("üìä An√°lisis del Dataset de Entrenamiento")
        
        try:
            df = pd.read_csv("data.csv")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("üìã Primeras filas del dataset:")
                st.dataframe(df.head(5), use_container_width=True)
                
                st.write("üìà Distribuci√≥n de clases:")
                counts = df['fail'].value_counts()
                st.write(f"- Normal (0): {counts.get(0, 0)} registros")
                st.write(f"- Fallo (1): {counts.get(1, 0)} registros")
            
            with col2:
                st.write("üìä Estad√≠sticas descriptivas:")
                st.dataframe(df.describe(), use_container_width=True)
                
                st.write("‚ÑπÔ∏è Informaci√≥n general:")
                st.write(f"- Filas: {df.shape[0]}")
                st.write(f"- Columnas: {df.shape[1]}")
                st.write(f"- Valores nulos: {df.isnull().sum().sum()}")
        
        except FileNotFoundError:
            st.warning("üìù Dataset no disponible para an√°lisis")
        except Exception as e:
            st.error(f"‚ùå Error en el an√°lisis: {str(e)}")
            
    # PESTA√ëA 3: EXPLICACI√ìN CON SHAP (C√ìDIGO CORREGIDO)
    with tab_explain:
        st.subheader("üìù Explicaci√≥n de la Predicci√≥n con SHAP")
        
        # DEBUG: Verificaci√≥n mejorada de SHAP
        try:
            import shap
            SHAP_AVAILABLE = True
        except ImportError as e:
            SHAP_AVAILABLE = False
            st.error(f"‚ùå Error importando SHAP: {e}")
        
        if 'input_data' not in st.session_state:
            st.info("‚ÑπÔ∏è Realiza una predicci√≥n primero para ver la explicaci√≥n.")
        else:
            try:
                if not SHAP_AVAILABLE:
                    st.warning("üîß SHAP no disponible temporalmente")
                    st.info("""
                    **Para habilitar explicaciones completas:**
                    - Reinicia la aplicaci√≥n
                    - Verifica que SHAP est√© instalado
                    """)
                    
                    # Mostrar los valores ingresados aunque no haya SHAP
                    st.subheader("üìã Valores ingresados para predicci√≥n")
                    feature_names = ['Footfall', 'Temp Mode', 'AQ', 'USS', 'CS', 'VOC', 'RP', 'IP', 'Temperature']
                    input_df = pd.DataFrame(st.session_state['input_data'], columns=feature_names)
                    st.dataframe(input_df, use_container_width=True)
                    
                else:
                    # Cargar modelo y datos
                    model = joblib.load('lr_best.pkl')
                    df = pd.read_csv("data.csv")
                    X = df.drop('fail', axis=1)
                    
                    # Preparar datos para SHAP
                    input_data = st.session_state['input_data']
                    input_scaled = st.session_state['input_scaled']
                    prediction = st.session_state['prediction']
                    probability = st.session_state['probability']
                    
                    # Crear explainer de SHAP - compatible con v0.48.0
                    with st.spinner("Calculando explicaci√≥n con SHAP..."):
                        # Para modelos lineales como Logistic Regression
                        explainer = shap.LinearExplainer(model, X)
                        shap_values = explainer(input_scaled)
                        
                        # Mostrar fuerza de la predicci√≥n
                        st.subheader("üìä Contribuci√≥n de cada caracter√≠stica")
                        
                        # Obtener nombres de caracter√≠sticas
                        feature_names = X.columns.tolist()
                        
                        # Crear un DataFrame con los valores SHAP
                        shap_df = pd.DataFrame({
                            'Caracter√≠stica': feature_names,
                            'Valor SHAP': shap_values.values[0],
                            'Impacto': ['Aumenta riesgo' if x > 0 else 'Reduce riesgo' for x in shap_values.values[0]]
                        }).sort_values('Valor SHAP', key=abs, ascending=False)
                        
                        # Mostrar tabla de contribuciones
                        st.dataframe(shap_df, use_container_width=True)
                        
                        # VISUALIZACI√ìN CORREGIDA - usar bar plot en lugar de force plot
                        st.subheader("üìà Contribuci√≥n de caracter√≠sticas (Gr√°fico de barras)")
                        
                        # Crear gr√°fico de barras horizontal
                        fig, ax = plt.subplots(figsize=(12, 8))
                        
                        # Ordenar por valor absoluto para mejor visualizaci√≥n
                        sorted_idx = np.argsort(np.abs(shap_values.values[0]))
                        
                        colors = ['red' if x > 0 else 'blue' for x in shap_values.values[0]]
                        
                        y_pos = np.arange(len(feature_names))
                        ax.barh(y_pos, shap_values.values[0][sorted_idx], color=np.array(colors)[sorted_idx], alpha=0.7)
                        ax.set_yticks(y_pos)
                        ax.set_yticklabels(np.array(feature_names)[sorted_idx])
                        ax.set_xlabel('Valor SHAP (Impacto en la predicci√≥n)')
                        ax.set_title('Contribuci√≥n de cada caracter√≠stica a la predicci√≥n')
                        ax.axvline(x=0, color='black', linestyle='--', alpha=0.5)
                        
                        # A√±adir valores en las barras
                        for i, v in enumerate(shap_values.values[0][sorted_idx]):
                            ax.text(v + (0.01 if v >= 0 else -0.05), i, f'{v:.3f}', 
                                   va='center', fontweight='bold', 
                                   color='black' if abs(v) < 0.1 else 'white')
                        
                        plt.tight_layout()
                        st.pyplot(fig)
                        
                        # VALORES ESPEC√çFICOS PARA DEBUG
                        with st.expander("üîç Valores detallados para diagn√≥stico"):
                            st.write("**Valor esperado (base value):**", explainer.expected_value)
                            st.write("**Valores SHAP:**", shap_values.values[0])
                            st.write("**Suma de valores SHAP:**", np.sum(shap_values.values[0]))
                            st.write("**Predicci√≥n final:**", explainer.expected_value + np.sum(shap_values.values[0]))
                        
                        # Explicaci√≥n en texto
                        st.subheader("üß† Interpretaci√≥n de la explicaci√≥n")
                        
                        # Encontrar las caracter√≠sticas m√°s influyentes
                        top_positive = shap_df.nlargest(3, 'Valor SHAP')
                        top_negative = shap_df.nsmallest(3, 'Valor SHAP')
                        
                        if prediction[0] == 1:
                            st.write("""
                            **üö® La m√°quina tiene alta probabilidad de fallo debido a:**
                            - Valores an√≥malos en los sensores con mayor impacto positivo
                            - Combinaci√≥n de factors que exceden los umbrales seguros
                            """)
                            
                            st.write("**üìà Factores que m√°s aumentan el riesgo:**")
                            for _, row in top_positive.iterrows():
                                st.write(f"  - **{row['Caracter√≠stica']}**: {row['Valor SHAP']:.3f}")
                                
                        else:
                            st.write("""
                            **‚úÖ La m√°quina opera normalmente porque:**
                            - Los valores de los sensores est√°n dentro de rangos normales
                            - Los factores que reducen el riesgo contrarrestan los de riesgo
                            """)
                            
                            st.write("**üìâ Factores que m√°s reducen el riesgo:**")
                            for _, row in top_negative.iterrows():
                                st.write(f"  - **{row['Caracter√≠stica']}**: {row['Valor SHAP']:.3f}")
                        
                        # Mostrar los valores reales ingresados
                        st.subheader("üìã Valores ingresados")
                        input_df = pd.DataFrame(input_data, columns=feature_names)
                        st.dataframe(input_df, use_container_width=True)
                    
            except Exception as e:
                st.error(f"‚ùå Error al generar la explicaci√≥n: {str(e)}")
                import traceback
                with st.expander("üîç Ver detalles del error"):
                    st.code(traceback.format_exc())

# ============================================================
# FIN SECCI√ìN: PREDECIR FALLOS
# ============================================================

# ============================================================
# SECCI√ìN: RENDIMIENTO DEL MODELO
# ============================================================
elif menu_opcion == "üìà Rendimiento del Modelo":
    st.header("üìà Rendimiento y M√©tricas del Modelo")
    
    try:
        # Cargar modelo, scaler y datos
        model = joblib.load('lr_best.pkl')
        scaler = joblib.load('scaler.pkl')
        df = pd.read_csv("data.csv")
        
        # Preparar datos para evaluaci√≥n
        X = df.drop('fail', axis=1)
        y = df['fail']
        X_scaled = scaler.transform(X)
        
        # Realizar predicciones
        y_pred = model.predict(X_scaled)
        y_pred_proba = model.predict_proba(X_scaled)[:, 1]
        
        st.success("‚úÖ Modelo y datos cargados exitosamente!")
        
        # Pesta√±as para organizar las m√©tricas
        tab1, tab2, tab3, tab4 = st.tabs(["üìä M√©tricas B√°sicas", "üìã Reporte Completo", "üéØ Matriz de Confusi√≥n", "üìà Curva ROC"])
        
        with tab1:
            st.subheader("üìä M√©tricas B√°sicas de Rendimiento")
            
            accuracy = accuracy_score(y, y_pred)
            precision = precision_score(y, y_pred)
            recall = recall_score(y, y_pred)
            f1 = f1_score(y, y_pred)
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Precisi√≥n (Accuracy)", f"{accuracy:.4f}")
            with col2:
                st.metric("Precisi√≥n (Precision)", f"{precision:.4f}")
            with col3:
                st.metric("Sensibilidad (Recall)", f"{recall:.4f}")
            with col4:
                st.metric("Puntuaci√≥n F1", f"{f1:.4f}")
            
            # Gr√°fico de barras de m√©tricas
            metrics_data = {
                'M√©trica': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],
                'Valor': [accuracy, precision, recall, f1]
            }
            metrics_df = pd.DataFrame(metrics_data)
            st.bar_chart(metrics_df.set_index('M√©trica'))
        
        with tab2:
            st.subheader("üìã Reporte de Clasificaci√≥n Completo")
            
            report = classification_report(y, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            
            st.dataframe(
                report_df.style
                .highlight_max(axis=0, color='#90EE90')
                .format('{:.4f}'),
                use_container_width=True
            )
            
            # Descargar reporte
            csv = report_df.to_csv(index=True)
            st.download_button(
                label="üì• Descargar Reporte CSV",
                data=csv,
                file_name="reporte_clasificacion.csv",
                mime="text/csv"
            )
        
        with tab3:
            st.subheader("üéØ Matriz de Confusi√≥n")
            
            cm = confusion_matrix(y, y_pred)
            
            fig, ax = plt.subplots(figsize=(6, 5))
            disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Normal', 'Fallo'])
            disp.plot(cmap='Blues', ax=ax, values_format='d')
            plt.title('Matriz de Confusi√≥n')
            st.pyplot(fig)
            
            # An√°lisis de la matriz
            st.info("**An√°lisis de la matriz:**")
            st.write(f"- **Verdaderos Negativos (TN):** {cm[0, 0]}")
            st.write(f"- **Falsos Positivos (FP):** {cm[0, 1]}")
            st.write(f"- **Falsos Negativos (FN):** {cm[1, 0]}")
            st.write(f"- **Verdaderos Positivos (TP):** {cm[1, 1]}")
        
        with tab4:
            st.subheader("üìà Curva ROC y AUC")
            
            fpr, tpr, thresholds = roc_curve(y, y_pred_proba)
            roc_auc = auc(fpr, tpr)
            
            fig, ax = plt.subplots(figsize=(8, 6))
            RocCurveDisplay.from_predictions(
                y, y_pred_proba,
                name=f"ROC curve (AUC = {roc_auc:.4f})",
                ax=ax
            )
            plt.plot([0, 1], [0, 1], 'k--', label='Clasificador aleatorio')
            plt.xlabel('Tasa de Falsos Positivos')
            plt.ylabel('Tasa de Verdaderos Positivos')
            plt.title('Curva ROC')
            plt.legend(loc='lower right')
            st.pyplot(fig)
            
            st.metric("√Årea bajo la curva (AUC)", f"{roc_auc:.4f}")
            
            # Interpretaci√≥n del AUC
            if roc_auc > 0.9:
                st.success("‚úÖ Excelente poder de discriminaci√≥n (AUC > 0.9)")
            elif roc_auc > 0.8:
                st.warning("‚ö†Ô∏è Buen poder de discriminaci√≥n (AUC > 0.8)")
            else:
                st.error("‚ùå Poder de discriminaci√≥n limitado (AUC < 0.8)")
        
        # Secci√≥n adicional de an√°lisis
        st.markdown("---")
        st.subheader("üìå An√°lisis Adicional")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Distribuci√≥n de probabilidades
            st.write("**Distribuci√≥n de probabilidades predichas:**")
            prob_df = pd.DataFrame({
                'Probabilidad': y_pred_proba,
                'Clase Real': y.map({0: 'Normal', 1: 'Fallo'})
            })
            st.bar_chart(prob_df.groupby('Clase Real')['Probabilidad'].mean())
        
        with col2:
            # M√©tricas por clase
            st.write("**Resumen por clase:**")
            class_summary = pd.DataFrame({
                'Clase': ['Normal (0)', 'Fallo (1)'],
                'Registros': [len(y[y == 0]), len(y[y == 1])],
                'Precisi√≥n': [report['0']['precision'], report['1']['precision']],
                'Recall': [report['0']['recall'], report['1']['recall']]
            })
            st.dataframe(class_summary, use_container_width=True)
                
    except FileNotFoundError:
        st.error("""
        ‚ùå No se encontraron los archivos necesarios. Por favor:
        1. Ve a la secci√≥n **ü§ñ Entrenar Modelo**
        2. Entrena el modelo primero
        3. Vuelve a esta secci√≥n
        """)
    except Exception as e:
        st.error(f"‚ùå Error al cargar los datos: {str(e)}")

# ============================================================
# SECCI√ìN: CONFIGURACI√ìN
# ============================================================
elif menu_opcion == "‚öôÔ∏è Configuraci√≥n":
    st.header("‚öôÔ∏è Configuraci√≥n del Sistema")
    
    st.subheader("üîß Ajustes de la Aplicaci√≥n")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.selectbox("Tema de la aplicaci√≥n", ["Claro", "Oscuro"])
        st.slider("Tama√±o de visualizaci√≥n", 1, 100, 80)
    
    with col2:
        st.number_input("L√≠mite de registros", 100, 10000, 1000)
        st.checkbox("Modo de alto contraste")
    
    st.subheader("üìÅ Gesti√≥n de Archivos")
    if st.button("üóëÔ∏è Limpiar modelos antiguos"):
        st.info("Funci√≥n de limpieza en desarrollo...")
    
    st.subheader("‚ÑπÔ∏è Informaci√≥n del Sistema")
    st.write(f"**Versi√≥n de Streamlit:** {st.__version__}")
    st.write("**Estado:** üü¢ Conectado")

# Footer
st.markdown("---")
st.caption("¬© 2024 Sistema de predicci√≥n de fallos de m√°quina | Desarrollado con Streamlit y Machine Learning")